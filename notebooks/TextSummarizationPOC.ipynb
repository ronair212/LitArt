{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "# append a new directory to sys.path\n",
    "# sys.path.append(os.path.dirname(os.path.dirname(__file__)))\n",
    "sys.path.append('/home/verma.shi/LLM/LitArt/data_module')\n",
    "sys.path.append('/home/verma.shi/LLM/LitArt/models')\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import pipeline, set_seed\n",
    "from transformers import get_linear_schedule_with_warmup, AdamW\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextSummaryDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 df,\n",
    "                 textprocessor,\n",
    "                 tokenizer,\n",
    "                 tokenizer_chapter_max_length=1024,\n",
    "                 tokenizer_summary_max_length=64,\n",
    "                 truncation=True,\n",
    "                 ):\n",
    "\n",
    "        self.df = df\n",
    "        self.textprocessor = textprocessor\n",
    "        self.chapter = df[\"chapter\"]\n",
    "        self.summary = df[\"summary_text\"]\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokenizer_chapter_max_length = tokenizer_chapter_max_length\n",
    "        self.tokenizer_summary_max_length = tokenizer_summary_max_length\n",
    "        self.truncation = truncation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.chapter)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        chapter = \"Summarize the following : \\n\" + str(self.textprocessor.process(self.chapter[idx])) + \"\\n\\nSummary:\"\n",
    "        summary = self.textprocessor.process(self.summary[idx])\n",
    "\n",
    "        input_encodings = self.tokenizer(chapter, max_length=self.tokenizer_chapter_max_length,padding=\"max_length\", truncation=self.truncation)\n",
    "\n",
    "        with self.tokenizer.as_target_tokenizer():\n",
    "            target_encodings = self.tokenizer(summary, max_length=self.tokenizer_summary_max_length,padding=\"max_length\", truncation=self.truncation)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(input_encodings[\"input_ids\"], dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(input_encodings[\"attention_mask\"], dtype=torch.long),\n",
    "            \"labels\": torch.tensor(target_encodings[\"input_ids\"], dtype=torch.long),\n",
    "            \"summary_mask\": torch.tensor(target_encodings[\"attention_mask\"], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# append a new directory to sys.path\n",
    "# sys.path.append(os.path.dirname(os.path.dirname(__file__)))\n",
    "sys.path.append('/home/verma.shi/LLM/LitArt/data_module')\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "import pandas as pd\n",
    "import lightning as L\n",
    "from data_preprocessor import TextPreprocessing\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class TextDataModule(L.LightningDataModule):\n",
    "    def __init__(self,\n",
    "                 train_path,\n",
    "                 test_path,\n",
    "                 val_path,\n",
    "                 textprocessor,\n",
    "                 tokenizer,\n",
    "                 tokenizer_chapter_max_length=1024,\n",
    "                 tokenizer_summary_max_length=64,\n",
    "                 truncation = True,\n",
    "                 batch_size: int = 32):\n",
    "\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # Initializing Paths\n",
    "        self.train_path = train_path\n",
    "        self.test_path = test_path\n",
    "        self.val_path = val_path\n",
    "\n",
    "        # Initializing Dataframes\n",
    "        self.train_df = None\n",
    "        self.test_df = None\n",
    "        self.val_df = None\n",
    "\n",
    "        # Textprocessor setup\n",
    "        self.textprocessor = textprocessor\n",
    "\n",
    "        # Tokenizer setup\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokenizer_chapter_max_length = tokenizer_chapter_max_length\n",
    "        self.tokenizer_summary_max_length = tokenizer_summary_max_length\n",
    "        self.truncation = truncation\n",
    "\n",
    "        # Batch size setup\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def prepare_data(self):\n",
    "         # Reading the train file\n",
    "        try:\n",
    "            self.train_df = pd.read_csv(self.train_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception raised while reading training file at path : {self.train_path} \\n Exception : {e}\")\n",
    "\n",
    "        # Reading the test file\n",
    "        try:\n",
    "            self.test_df = pd.read_csv(self.test_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception raised while reading test file at path : {self.test_path} \\n Exception : {e}\")\n",
    "\n",
    "        # Reading the validation file\n",
    "        try:\n",
    "            self.val_df = pd.read_csv(self.val_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception raised while reading validation file at path : {self.val_path} \\n Exception : {e}\")\n",
    "\n",
    "    def total_documents(self):\n",
    "        \n",
    "        total_documents = self.train_df.shape[0] + self.test_df.shape[0] + self.val_df.shape[0]\n",
    "\n",
    "        return total_documents\n",
    "\n",
    "\n",
    "    def setup(self, stage= None):\n",
    "        self.train_dataset = TextSummaryDataset(\n",
    "            df=self.train_df,\n",
    "            textprocessor=self.textprocessor,\n",
    "            tokenizer=self.tokenizer,\n",
    "            tokenizer_chapter_max_length=self.tokenizer_chapter_max_length,\n",
    "            tokenizer_summary_max_length=self.tokenizer_summary_max_length,\n",
    "            truncation=self.truncation)\n",
    "\n",
    "        self.val_dataset = TextSummaryDataset(\n",
    "            df=self.val_df,\n",
    "            textprocessor=self.textprocessor,\n",
    "            tokenizer=self.tokenizer,\n",
    "            tokenizer_chapter_max_length=self.tokenizer_chapter_max_length,\n",
    "            tokenizer_summary_max_length=self.tokenizer_summary_max_length,\n",
    "            truncation=self.truncation)\n",
    "\n",
    "        self.test_dataset = TextSummaryDataset(\n",
    "            df=self.test_df,\n",
    "            textprocessor=self.textprocessor,\n",
    "            tokenizer=self.tokenizer,\n",
    "            tokenizer_chapter_max_length=self.tokenizer_chapter_max_length,\n",
    "            tokenizer_summary_max_length=self.tokenizer_summary_max_length,\n",
    "            truncation=self.truncation)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=0)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=0)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TextSummaryModel(L.LightningModule):\n",
    "    def __init__(self,model,\n",
    "                     total_documents = 5000,\n",
    "                     epochs=2):\n",
    "        super(TextSummaryModel,self).__init__()\n",
    "        self.model = model\n",
    "        self.epochs = int(epochs)\n",
    "        self.total_documents = int(total_documents)\n",
    "\n",
    "\n",
    "    def set_model(self,model):\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, \n",
    "                input_ids, \n",
    "                attention_mask, \n",
    "                labels = None, \n",
    "                decoder_attention_mask = None):\n",
    "        \n",
    "        outputs = self.model(input_ids=input_ids,\n",
    "                             attention_mask=attention_mask,\n",
    "                             labels=labels,\n",
    "                             decoder_attention_mask=decoder_attention_mask)\n",
    "\n",
    "        return outputs.loss, outputs.logits\n",
    "\n",
    "    def training_step(self,batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        decoder_attention_mask = batch[\"summary_mask\"]\n",
    "\n",
    "        loss , output = self(input_ids = input_ids,\n",
    "                            attention_mask = attention_mask,\n",
    "                            labels = labels,\n",
    "                            decoder_attention_mask = decoder_attention_mask)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self , batch , batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        decoder_attention_mask = batch[\"summary_mask\"]\n",
    "\n",
    "        loss , output = self(input_ids = input_ids,\n",
    "                            attention_mask = attention_mask,\n",
    "                            labels = labels,\n",
    "                            decoder_attention_mask = decoder_attention_mask)\n",
    "\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        decoder_attention_mask = batch[\"summary_mask\"]\n",
    "        loss, output = self(input_ids=input_ids, \n",
    "                            attention_mask=attention_mask,\n",
    "                            labels = labels,\n",
    "                            decoder_attention_mask = decoder_attention_mask)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.model.parameters(), lr=0.0001)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=500,\n",
    "                num_training_steps=self.epochs*self.total_documents)\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "#Loading the data\n",
    "train_path = \"/work/LitArt/data/generated_summaries/train_dataset_with_summaries.csv\"\n",
    "test_path = \"/work/LitArt/data/generated_summaries/test_dataset_with_summaries.csv\"\n",
    "val_path = \"/work/LitArt/data/generated_summaries/validation_dataset_with_summaries.csv\"\n",
    "\n",
    "\n",
    "#Loading the model and tokenizer\n",
    "base_model_name = \"google/flan-t5-base\"\n",
    "tokenizer_name = \"google/flan-t5-base\"\n",
    "cache_dir = \"/work/LitArt/cache\"\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(base_model_name,cache_dir=cache_dir).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name,cache_dir=cache_dir)\n",
    "\n",
    "#Initializing the dataloaders\n",
    "textpreprocessor = TextPreprocessing()\n",
    "textmodule = TextDataModule(train_path=train_path,\n",
    "                                    val_path=val_path,\n",
    "                                    test_path=test_path,\n",
    "                                    textprocessor=textpreprocessor,\n",
    "                                    tokenizer=tokenizer,\n",
    "                                    tokenizer_chapter_max_length=1024,\n",
    "                                    tokenizer_summary_max_length=64,\n",
    "                                    truncation=True)\n",
    "\n",
    "textmodule.prepare_data()\n",
    "textmodule.setup()\n",
    "total_documents = textmodule.total_documents()\n",
    "\n",
    "#Model Parameters\n",
    "batch_size = 64\n",
    "chapter_length = 512\n",
    "summary_length = 64\n",
    "epochs = 1\n",
    "log_path =  \"/work/LitArt/verma/lightning_logs\"\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filename=\"{epoch}-{val_loss:.2f}\",\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    verbose=True,\n",
    "    save_top_k=1,\n",
    ")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    callbacks=[\n",
    "                checkpoint_callback,\n",
    "            ],\n",
    "    max_epochs = epochs,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    default_root_dir = log_path\n",
    ")\n",
    "\n",
    "\n",
    "#Loading the model\n",
    "model = TextSummaryModel(model=base_model,epochs=epochs,total_documents=total_documents)\n",
    "\n",
    "#Fitting the model\n",
    "trainer.fit(model, textmodule)\n",
    "\n",
    "best_model_path = checkpoint_callback.best_model_path\n",
    "print(f'Best Model Path = {best_model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: nvidia-smi: command not found\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/work/LitArt/data/generated_summaries/train_dataset_with_summaries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chapter</th>\n",
       "      <th>summary_text</th>\n",
       "      <th>__index_level_0__</th>\n",
       "      <th>generated_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one evening as i was lying flat on the deck of...</td>\n",
       "      <td>from the deck of his steamboat marlow overhear...</td>\n",
       "      <td>5664</td>\n",
       "      <td>On a steamboat, the narrator overhears a conve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the river--seemed to beckon with a dishonourin...</td>\n",
       "      <td>from the deck of his steamboat marlow overhear...</td>\n",
       "      <td>5664</td>\n",
       "      <td>Narrator travels up a mysterious river, encoun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air for a while--and on we went again into the...</td>\n",
       "      <td>from the deck of his steamboat marlow overhear...</td>\n",
       "      <td>5664</td>\n",
       "      <td>The passage describes a journey through a dens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>instructed and what he knew was this--that sho...</td>\n",
       "      <td>from the deck of his steamboat marlow overhear...</td>\n",
       "      <td>5664</td>\n",
       "      <td>A fireman, fearing an evil spirit in the boile...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we were till next morning moreover he pointed ...</td>\n",
       "      <td>from the deck of his steamboat marlow overhear...</td>\n",
       "      <td>5664</td>\n",
       "      <td>Delayed by sensible caution, the narrator navi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10663</th>\n",
       "      <td>so in this case you must have made extensive c...</td>\n",
       "      <td>isabel decides that no harm can come to her fr...</td>\n",
       "      <td>9514</td>\n",
       "      <td>Countess and Madame Merle discuss Isabel Arche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10664</th>\n",
       "      <td>if miss archer s to become her mother it s sur...</td>\n",
       "      <td>isabel decides that no harm can come to her fr...</td>\n",
       "      <td>9514</td>\n",
       "      <td>The Countess and Madame Merle discuss potentia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10665</th>\n",
       "      <td>actus quartus enter one of the frenchmen with ...</td>\n",
       "      <td>one of the french lords and a band of soldiers...</td>\n",
       "      <td>8794</td>\n",
       "      <td>French soldiers plan to ambush Lord E. They us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10666</th>\n",
       "      <td>true what is not holie that we sweare not by b...</td>\n",
       "      <td>one of the french lords and a band of soldiers...</td>\n",
       "      <td>8794</td>\n",
       "      <td>A person questions swearing by unholy things, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10667</th>\n",
       "      <td>of the place cap e hath the count all this int...</td>\n",
       "      <td>one of the french lords and a band of soldiers...</td>\n",
       "      <td>8794</td>\n",
       "      <td>Count Rossillion prepares to leave for France ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10668 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 chapter  \\\n",
       "0      one evening as i was lying flat on the deck of...   \n",
       "1      the river--seemed to beckon with a dishonourin...   \n",
       "2      air for a while--and on we went again into the...   \n",
       "3      instructed and what he knew was this--that sho...   \n",
       "4      we were till next morning moreover he pointed ...   \n",
       "...                                                  ...   \n",
       "10663  so in this case you must have made extensive c...   \n",
       "10664  if miss archer s to become her mother it s sur...   \n",
       "10665  actus quartus enter one of the frenchmen with ...   \n",
       "10666  true what is not holie that we sweare not by b...   \n",
       "10667  of the place cap e hath the count all this int...   \n",
       "\n",
       "                                            summary_text  __index_level_0__  \\\n",
       "0      from the deck of his steamboat marlow overhear...               5664   \n",
       "1      from the deck of his steamboat marlow overhear...               5664   \n",
       "2      from the deck of his steamboat marlow overhear...               5664   \n",
       "3      from the deck of his steamboat marlow overhear...               5664   \n",
       "4      from the deck of his steamboat marlow overhear...               5664   \n",
       "...                                                  ...                ...   \n",
       "10663  isabel decides that no harm can come to her fr...               9514   \n",
       "10664  isabel decides that no harm can come to her fr...               9514   \n",
       "10665  one of the french lords and a band of soldiers...               8794   \n",
       "10666  one of the french lords and a band of soldiers...               8794   \n",
       "10667  one of the french lords and a band of soldiers...               8794   \n",
       "\n",
       "                                       generated_summary  \n",
       "0      On a steamboat, the narrator overhears a conve...  \n",
       "1      Narrator travels up a mysterious river, encoun...  \n",
       "2      The passage describes a journey through a dens...  \n",
       "3      A fireman, fearing an evil spirit in the boile...  \n",
       "4      Delayed by sensible caution, the narrator navi...  \n",
       "...                                                  ...  \n",
       "10663  Countess and Madame Merle discuss Isabel Arche...  \n",
       "10664  The Countess and Madame Merle discuss potentia...  \n",
       "10665  French soldiers plan to ambush Lord E. They us...  \n",
       "10666  A person questions swearing by unholy things, ...  \n",
       "10667  Count Rossillion prepares to leave for France ...  \n",
       "\n",
       "[10668 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
